{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import functools\n",
    "import glob\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CandidateInfoTuple = namedtuple(\n",
    "    'CandidateInfoTuple',\n",
    "    'isNodule_bool, diameter_mm, series_uid, center_xyz',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getCandidateInfoList comments\n",
    "\n",
    "* *@functools.lru_cache(1) - in-memory cache decorator*\n",
    "* *requireOnDisk_bool=True - defaults to screening out series from data subsets that aren't in place yet.*\n",
    "* *We construct a set with all series_uids that are present on disk. This will let us use the data, even if we haven't downloaded all of the subsets yet.*\n",
    "* *For each of the candidate entries for a given series_uid, we loop through the annotations we collected earlier for the same series_uid and see if the two coordinates are\n",
    "close enough to consider them the same nodule.*\n",
    "* *If we don’t find diameter information for a nodule, that’s fine; we’ll just treat the nodule as having a 0.0 diameter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(1)\n",
    "def getCandidateInfoList(requireOnDisk_bool=True):\n",
    "    mhd_list = glob.glob('data/luna/subset*/*.mhd')\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "\n",
    "    # First we need to group our annotations by series_uid, as that’s the first key we’ll use to cross-reference each row from the two files.\n",
    "    diameter_dict = {}\n",
    "    with open('data/annotations.csv', 'r') as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "            annotationCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "            annotationDiameter_mm = float(row[4])\n",
    "\n",
    "            diameter_dict.setdefault(series_uid, []).append(\n",
    "                (annotationCenter_xyz, annotationDiameter_mm)\n",
    "            )\n",
    "\n",
    "    # Now we’ll build our full list of candidates using the information in the candidates.csv file.\n",
    "    candidateInfo_list = []\n",
    "    with open('data/annotations.csv', 'r') as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "\n",
    "            # If a series_uid isn’t present, it’s in a subset we don’t have on disk, so we should skip it.\n",
    "            if series_uid not in presentOnDisk_set and requireOnDisk_bool:\n",
    "                continue\n",
    "\n",
    "            isNodule_bool = bool(int(row[4]))\n",
    "            candidateCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "\n",
    "            candidateDiameter_mm = 0.0\n",
    "            for annotation_tup in diameter_dict.get(series_uid, []):\n",
    "                annotationCenter_xyz, annotationDiameter_mm = annotation_tup\n",
    "                for i in range(3):\n",
    "                    delta_mm = abs(candidateCenter_xyz[i] - annotationCenter_xyz[i])\n",
    "                    \n",
    "                    # Divides the diameter by 2 to get the radius, and divides the radius by 2 to require that the two nodule center points not be too far apart relative to the size of the nodule. \n",
    "                    # (This results in a bounding-box check, not a true distance check.) \n",
    "                    if delta_mm > annotationDiameter_mm / 4:\n",
    "                        break\n",
    "                    else:\n",
    "                        candidateDiameter_mm = annotationDiameter_mm\n",
    "                        break\n",
    "\n",
    "                candidateInfo_list.append(CandidateInfoTuple(\n",
    "                    isNodule_bool,\n",
    "                    candidateDiameter_mm,\n",
    "                    series_uid,\n",
    "                    candidateCenter_xyz,\n",
    "                ))\n",
    "\n",
    "    # This means we have all of the actual nodule samples starting with the largest first, \n",
    "    # followed by all of the non-nodule samples (which don’t have nodule size information).\n",
    "    candidateInfo_list.sort(reverse=True)\n",
    "    return candidateInfo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
